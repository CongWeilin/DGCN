{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from utils import load_data, process_graph_data\n",
    "from utils import package_mxl, adj_rw_norm\n",
    "from utils import sparse_mx_to_torch_sparse_tensor\n",
    "from utils import ResultRecorder\n",
    "\n",
    "from model import GCN, GCNBias, SGC, ResGCN, GCNII, APPNP\n",
    "from layers import GraphConv\n",
    "from load_semigcn_data import load_data_gcn\n",
    "from data_loader import DataLoader\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import pairwise_distances\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mticker\n",
    "from scipy.sparse.csgraph import connected_components\n",
    "\n",
    "from tqdm import trange\n",
    "import numpy as np\n",
    "import copy \n",
    "import time\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "DATASET = 'citeseer'\n",
    "SAVE_DIR = './exp_results/figures/%s/'%DATASET\n",
    "\n",
    "layers = [i for i in range(2,11)]\n",
    "repeats = [i for i in range(10)]   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ALGORITHM in ['GCN', 'GCNBias', 'SGC', 'ResGCN', 'GCNII', 'APPNP']:\n",
    "    dM_all = []\n",
    "    dM_after_all = []\n",
    "    dM_before_one_model = []\n",
    "    dM_after_one_model = []\n",
    "    \n",
    "    inner_dist_all = []\n",
    "    cross_dist_all = []\n",
    "    \n",
    "    inner_dist_after_all = []\n",
    "    inner_dist_one_model = []\n",
    "    cross_dist_after_all = []\n",
    "    cross_dist_one_model = []\n",
    "\n",
    "    sigW_all = []\n",
    "    sigW_after_all = []\n",
    "\n",
    "    test_acc_all = []\n",
    "\n",
    "    for layer in layers:\n",
    "        dM_current = list()\n",
    "        sigW_current = list()\n",
    "        dM_after_current = list()\n",
    "        sigW_after_current = list()\n",
    "        test_acc_current = list()\n",
    "        inner_dist_current = list()\n",
    "        cross_dist_current = list()\n",
    "        inner_dist_after_current = list()\n",
    "        cross_dist_after_current = list()\n",
    "\n",
    "        for repeat in repeats:\n",
    "            save_path = os.path.join('exp_results/%s/'%DATASET, \n",
    "                                 'results_%s_L%d_repteat%d.pkl'%(DATASET, layer, repeat))\n",
    "            with open(save_path, 'rb') as f:\n",
    "                results_list = pickle.load(f)\n",
    "\n",
    "            for result in results_list:\n",
    "                if result.note == '%s (L=%d)'%(ALGORITHM, layer):\n",
    "                    dM_current.append(result.dM_before[-1]*result.dM_before[0])\n",
    "            \n",
    "                    sigW_ = list()\n",
    "                    for k, v in result.w_sigval_before.items():\n",
    "                        if 'gcs.0' in k:\n",
    "                            continue\n",
    "                        elif 'gcs' in k:\n",
    "                            sigW_.append(v)\n",
    "                    sigW_ = np.mean(sigW_) if len(sigW_) > 0 else 1\n",
    "                    sigW_current.append(sigW_)\n",
    "\n",
    "                    dM_after_current.append(result.dM_after[-1]*result.dM_after[0])\n",
    "                    sigW_ = list()\n",
    "                    for k, v in result.w_sigval_after.items():\n",
    "                        if 'gcs' in k:\n",
    "                            sigW_.append(v)\n",
    "                    sigW_ = np.mean(sigW_) if len(sigW_) > 0 else 1\n",
    "                    sigW_after_current.append(sigW_)\n",
    "\n",
    "                    test_acc_current.append(result.test_acc)\n",
    "                    inner_dist_current.append(result.inner_dist[-1])\n",
    "                    cross_dist_current.append(result.cross_dist[-1])\n",
    "                    inner_dist_after_current.append(result.inner_dist_after[-1])\n",
    "                    cross_dist_after_current.append(result.cross_dist_after[-1])\n",
    "                    \n",
    "                    if layer == max(layers)-1:\n",
    "                        inner_dist_one_model.append(result.inner_dist_after)\n",
    "                        cross_dist_one_model.append(result.cross_dist_after)\n",
    "                        dM_before_one_model.append(result.dM_before)\n",
    "                        dM_after_one_model.append(result.dM_after)\n",
    "\n",
    "\n",
    "        dM_all.append(dM_current)\n",
    "        sigW_all.append(sigW_current)\n",
    "        dM_after_all.append(dM_after_current)\n",
    "        sigW_after_all.append(sigW_after_current)\n",
    "        test_acc_all.append(test_acc_current)\n",
    "        \n",
    "        inner_dist_all.append(inner_dist_current)\n",
    "        cross_dist_all.append(cross_dist_current)\n",
    "        inner_dist_after_all.append(inner_dist_after_current)\n",
    "        cross_dist_after_all.append(cross_dist_after_current)\n",
    "        \n",
    "    ###################\n",
    "    test_acc_all = np.array(test_acc_all) \n",
    "    fig, axs = plt.subplots()\n",
    "\n",
    "    y_vals = np.mean(test_acc_all, axis=1)\n",
    "    y_stds = np.std(test_acc_all, axis=1)\n",
    "    x_vals = np.arange(len(y_vals))+2\n",
    "    axs.plot(x_vals, y_vals, label='Testing')\n",
    "    axs.fill_between(x_vals, y_vals-y_stds, y_vals+y_stds ,alpha=0.3)\n",
    "\n",
    "    plt.title('%s: Testing F1-score / Num of layers'%ALGORITHM)\n",
    "    axs.set_xlabel('Num of layers')\n",
    "    axs.set_ylabel('F1-score')\n",
    "    axs.grid(True)\n",
    "    plt.gca().xaxis.set_major_locator(mticker.MultipleLocator(1))\n",
    "    fig.tight_layout()\n",
    "    plt.legend()\n",
    "    plt.savefig(SAVE_DIR+'testing_f1_score_%s_%s.pdf'%(DATASET, ALGORITHM))\n",
    "    plt.close()\n",
    "    ####################\n",
    "    fig, axs = plt.subplots()\n",
    "    \n",
    "    y_vals = np.mean(dM_all, axis=1)\n",
    "    y_stds = np.std(dM_all, axis=1)\n",
    "    x_vals = np.arange(len(y_vals))+2\n",
    "    axs.plot(x_vals, y_vals, label='Before training')\n",
    "    axs.fill_between(x_vals, y_vals-y_stds, y_vals+y_stds ,alpha=0.3)\n",
    "\n",
    "    plt.title('%s: $d_M(H^{(\\ell)})$ / Num of layers'%ALGORITHM)\n",
    "    axs.set_xlabel('Num of layers')\n",
    "    axs.set_ylabel('$d_M(H^{(\\ell)})$')\n",
    "    axs.grid(True)\n",
    "    plt.gca().xaxis.set_major_locator(mticker.MultipleLocator(1))\n",
    "    fig.tight_layout()\n",
    "    plt.legend()\n",
    "    plt.savefig(SAVE_DIR+'dM_%s_%s_before.pdf'%(DATASET, ALGORITHM))\n",
    "    plt.close()\n",
    "    ####################\n",
    "    fig, axs = plt.subplots()\n",
    "    \n",
    "    y_vals = np.mean(dM_after_all, axis=1)\n",
    "    y_stds = np.std(dM_after_all, axis=1)\n",
    "    x_vals = np.arange(len(y_vals))+2\n",
    "    axs.plot(x_vals, y_vals, label='After training')\n",
    "    axs.fill_between(x_vals, y_vals-y_stds, y_vals+y_stds ,alpha=0.3)\n",
    "\n",
    "    plt.title('%s: $d_M(H^{(\\ell)})$ / Num of layers'%ALGORITHM)\n",
    "    axs.set_xlabel('Num of layers')\n",
    "    axs.set_ylabel('$d_M(H^{(\\ell)})$')\n",
    "    axs.grid(True)\n",
    "    plt.gca().xaxis.set_major_locator(mticker.MultipleLocator(1))\n",
    "    fig.tight_layout()\n",
    "    plt.legend()\n",
    "    plt.savefig(SAVE_DIR+'dM_%s_%s_after.pdf'%(DATASET, ALGORITHM))\n",
    "    plt.close()\n",
    "    ####################\n",
    "    fig, axs = plt.subplots()\n",
    "    \n",
    "    # dM_before_one_model = np.array(dM_before_one_model) \n",
    "    y_vals = np.mean(dM_before_one_model, axis=1)\n",
    "    y_stds = np.std(dM_before_one_model, axis=1)\n",
    "    x_vals = np.arange(len(y_vals))+2\n",
    "    axs.plot(x_vals, y_vals, label='Before training')\n",
    "    axs.fill_between(x_vals, y_vals-y_stds, y_vals+y_stds ,alpha=0.3)\n",
    "    \n",
    "    # dM_after_one_model = np.array(dM_after_one_model) \n",
    "    y_vals = np.mean(dM_after_one_model, axis=1)\n",
    "    y_stds = np.std(dM_after_one_model, axis=1)\n",
    "    x_vals = np.arange(len(y_vals))+2\n",
    "    axs.plot(x_vals, y_vals, label='After training')\n",
    "    axs.fill_between(x_vals, y_vals-y_stds, y_vals+y_stds ,alpha=0.3)\n",
    "\n",
    "    plt.title('%s: $d_M(H^{(\\ell)})$ / Num of layers'%ALGORITHM)\n",
    "    axs.set_xlabel('Num of layers')\n",
    "    axs.set_ylabel('$d_M(H^{(\\ell)})$')\n",
    "    axs.grid(True)\n",
    "    plt.gca().xaxis.set_major_locator(mticker.MultipleLocator(1))\n",
    "    fig.tight_layout()\n",
    "    plt.legend()\n",
    "    plt.savefig(SAVE_DIR+'dM_%s_%s_one_model.pdf'%(DATASET, ALGORITHM))\n",
    "    plt.close()\n",
    "    ####################\n",
    "    fig, axs = plt.subplots()\n",
    "\n",
    "    inner_dist_all = np.array(inner_dist_all) \n",
    "    y_vals = np.mean(inner_dist_all, axis=1)\n",
    "    y_stds = np.std(inner_dist_all, axis=1)\n",
    "    x_vals = np.arange(len(y_vals))+2\n",
    "    axs.plot(x_vals, y_vals, label='Inner class distance')\n",
    "    axs.fill_between(x_vals, y_vals-y_stds, y_vals+y_stds ,alpha=0.3)\n",
    "    \n",
    "    cross_dist_all = np.array(cross_dist_all) \n",
    "    y_vals = np.mean(cross_dist_all, axis=1)\n",
    "    y_stds = np.std(cross_dist_all, axis=1)\n",
    "    x_vals = np.arange(len(y_vals))+2\n",
    "    axs.plot(x_vals, y_vals, label='Cross class distance')\n",
    "    axs.fill_between(x_vals, y_vals-y_stds, y_vals+y_stds ,alpha=0.3)\n",
    "\n",
    "    plt.title('%s: Pairwise Euclidean distance / Num of layers'%ALGORITHM)\n",
    "    axs.set_xlabel('Num of layers')\n",
    "    axs.set_ylabel('Pairwise Euclidean distance')\n",
    "    axs.grid(True)\n",
    "    plt.gca().xaxis.set_major_locator(mticker.MultipleLocator(1))\n",
    "    fig.tight_layout()\n",
    "    plt.legend()\n",
    "    plt.savefig(SAVE_DIR+'pairwise_euclidean_distance_%s_%s.pdf'%(DATASET, ALGORITHM))\n",
    "    plt.close()\n",
    "    ####################\n",
    "    fig, axs = plt.subplots()\n",
    "\n",
    "    inner_dist_all = np.array(inner_dist_one_model) \n",
    "    y_vals = np.mean(inner_dist_all, axis=0)\n",
    "    y_stds = np.std(inner_dist_all, axis=0)\n",
    "    x_vals = np.arange(len(y_vals))+2\n",
    "    axs.plot(x_vals, y_vals, label='Inner class distance')\n",
    "    axs.fill_between(x_vals, y_vals-y_stds, y_vals+y_stds ,alpha=0.3)\n",
    "    \n",
    "    cross_dist_all = np.array(cross_dist_one_model) \n",
    "    y_vals = np.mean(cross_dist_all, axis=0)\n",
    "    y_stds = np.std(cross_dist_all, axis=0)\n",
    "    x_vals = np.arange(len(y_vals))+2\n",
    "    axs.plot(x_vals, y_vals, label='Cross class distance')\n",
    "    axs.fill_between(x_vals, y_vals-y_stds, y_vals+y_stds ,alpha=0.3)\n",
    "\n",
    "    plt.title('%s: Pairwise Euclidean distance / Num of layers'%ALGORITHM)\n",
    "    axs.set_xlabel('Num of layers')\n",
    "    axs.set_ylabel('Pairwise Euclidean distance')\n",
    "    axs.grid(True)\n",
    "    plt.gca().xaxis.set_major_locator(mticker.MultipleLocator(1))\n",
    "    fig.tight_layout()\n",
    "    plt.legend()\n",
    "    plt.savefig(SAVE_DIR+'pairwise_euclidean_distance_%s_%s_one_model.pdf'%(DATASET, ALGORITHM))\n",
    "    plt.close()\n",
    "    ####################\n",
    "    fig, axs = plt.subplots()\n",
    "\n",
    "    inner_dist_all = np.array(inner_dist_after_all) \n",
    "    y_vals = np.mean(inner_dist_all, axis=1)\n",
    "    y_stds = np.std(inner_dist_all, axis=1)\n",
    "    x_vals = np.arange(len(y_vals))+2\n",
    "    axs.plot(x_vals, y_vals, label='Inner class distance (After)')\n",
    "    axs.fill_between(x_vals, y_vals-y_stds, y_vals+y_stds ,alpha=0.3)\n",
    "    \n",
    "    cross_dist_all = np.array(cross_dist_after_all) \n",
    "    y_vals = np.mean(cross_dist_all, axis=1)\n",
    "    y_stds = np.std(cross_dist_all, axis=1)\n",
    "    x_vals = np.arange(len(y_vals))+2\n",
    "    axs.plot(x_vals, y_vals, label='Cross class distance (After)')\n",
    "    axs.fill_between(x_vals, y_vals-y_stds, y_vals+y_stds ,alpha=0.3)\n",
    "\n",
    "    plt.title('%s: Pairwise Euclidean distance / Num of layers'%ALGORITHM)\n",
    "    axs.set_xlabel('Num of layers')\n",
    "    axs.set_ylabel('Pairwise Euclidean distance')\n",
    "    axs.grid(True)\n",
    "    plt.gca().xaxis.set_major_locator(mticker.MultipleLocator(1))\n",
    "    fig.tight_layout()\n",
    "    plt.legend()\n",
    "    plt.savefig(SAVE_DIR+'pairwise_euclidean_distance_%s_%s_after.pdf'%(DATASET, ALGORITHM))\n",
    "    plt.close()\n",
    "    ####################\n",
    "    sigW_all = np.array(sigW_all) \n",
    "    fig, axs = plt.subplots()\n",
    "\n",
    "    y_vals = np.mean(sigW_all, axis=1)\n",
    "    y_stds = np.std(sigW_all, axis=1)\n",
    "    x_vals = np.arange(len(y_vals))+2\n",
    "    axs.plot(x_vals, y_vals, label='Before training')\n",
    "    axs.fill_between(x_vals, y_vals-y_stds, y_vals+y_stds ,alpha=0.3)\n",
    "    \n",
    "    y_vals = np.mean(sigW_after_all, axis=1)\n",
    "    y_stds = np.std(sigW_after_all, axis=1)\n",
    "    x_vals = np.arange(len(y_vals))+2\n",
    "    axs.plot(x_vals, y_vals, label='After training')\n",
    "    axs.fill_between(x_vals, y_vals-y_stds, y_vals+y_stds ,alpha=0.3)\n",
    "    \n",
    "    plt.title('%s: $\\lambda_\\max(W^{(\\ell)})$ / Num of layers'%ALGORITHM)\n",
    "    axs.set_xlabel('Num of layers')\n",
    "    axs.set_ylabel('$\\lambda_\\max(W^{(\\ell)})$')\n",
    "    axs.grid(True)\n",
    "    plt.gca().xaxis.set_major_locator(mticker.MultipleLocator(1))\n",
    "    fig.tight_layout()\n",
    "    plt.legend()\n",
    "    plt.savefig(SAVE_DIR+'sigW_%s_%s.pdf'%(DATASET, ALGORITHM))\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGC (L=10)\n",
      "GCN (L=10)\n",
      "GCNBias (L=10)\n",
      "ResGCN (L=10)\n",
      "APPNP (L=10)\n",
      "GCNII (L=10)\n"
     ]
    }
   ],
   "source": [
    "for result in results_list:\n",
    "    print(result.note)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gcs.0.linear.weight': 1.1526110172271729,\n",
       " 'gcs.1.linear.weight': 1.158475637435913,\n",
       " 'gcs.2.linear.weight': 1.1382489204406738,\n",
       " 'gcs.3.linear.weight': 1.1306782960891724,\n",
       " 'gcs.4.linear.weight': 1.1244324445724487,\n",
       " 'gcs.5.linear.weight': 1.0891273021697998,\n",
       " 'gcs.6.linear.weight': 1.1014307737350464,\n",
       " 'gcs.7.linear.weight': 1.1215291023254395,\n",
       " 'gcs.8.linear.weight': 1.0771151781082153,\n",
       " 'gcs.9.linear.weight': 1.1258124113082886}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.w_sigval_before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([1.        , 0.55944998, 0.54341049, 0.53479422, 0.52992572,\n",
       "        0.52668019, 0.52448317, 0.52292475, 0.521804  , 0.52098311]),\n",
       " array([1.        , 0.58980613, 0.57254562, 0.56311345, 0.55782612,\n",
       "        0.5542882 , 0.55189836, 0.5502022 , 0.54898326, 0.54809056]),\n",
       " array([1.        , 0.49728911, 0.48381407, 0.4765519 , 0.47247124,\n",
       "        0.46974386, 0.46789797, 0.46658612, 0.46564156, 0.46494855]),\n",
       " array([1.        , 0.53108526, 0.51623642, 0.50825655, 0.5037566 ,\n",
       "        0.50075692, 0.49872614, 0.49728512, 0.49624817, 0.49548819]),\n",
       " array([1.        , 0.53704024, 0.5217603 , 0.51343281, 0.50878206,\n",
       "        0.50567181, 0.50357297, 0.50208348, 0.50101318, 0.50022919]),\n",
       " array([1.        , 0.51569108, 0.50178458, 0.494364  , 0.49016051,\n",
       "        0.48735425, 0.48544949, 0.48409525, 0.48311902, 0.4824024 ]),\n",
       " array([1.        , 0.58599296, 0.56928622, 0.56023669, 0.55513845,\n",
       "        0.55173053, 0.54942501, 0.54778813, 0.54661097, 0.54574842]),\n",
       " array([1.        , 0.57526765, 0.55861286, 0.54957313, 0.54450904,\n",
       "        0.54112382, 0.53883864, 0.53721693, 0.53605179, 0.53519843]),\n",
       " array([1.        , 0.5597991 , 0.54389096, 0.53521079, 0.53036655,\n",
       "        0.52712401, 0.52493663, 0.52338375, 0.52226804, 0.5214507 ]),\n",
       " array([1.        , 0.60521192, 0.58734082, 0.57769925, 0.57226317,\n",
       "        0.56864166, 0.56619421, 0.56446039, 0.56321524, 0.56230437])]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dM_after_one_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([1.        , 0.04551556, 0.04085813, 0.03834421, 0.03716378,\n",
       "        0.03642824, 0.03598481, 0.0356932 , 0.03550011, 0.03536795]),\n",
       " array([1.        , 0.04555687, 0.040893  , 0.03837948, 0.0372031 ,\n",
       "        0.03647097, 0.03603011, 0.03574038, 0.03554861, 0.03541738]),\n",
       " array([1.        , 0.04554553, 0.04086448, 0.03834916, 0.03716548,\n",
       "        0.03643025, 0.03598705, 0.0356963 , 0.03550403, 0.0353727 ]),\n",
       " array([1.        , 0.04500945, 0.04034941, 0.03782241, 0.03664486,\n",
       "        0.0359102 , 0.03546898, 0.03517905, 0.03498753, 0.03485662]),\n",
       " array([1.        , 0.04528115, 0.04060515, 0.03807699, 0.0368981 ,\n",
       "        0.03616394, 0.03572288, 0.03543332, 0.03524203, 0.03511134]),\n",
       " array([1.        , 0.04533132, 0.04065386, 0.03814687, 0.03696962,\n",
       "        0.03623879, 0.03579876, 0.03551002, 0.0353191 , 0.03518862]),\n",
       " array([1.        , 0.04559877, 0.04095676, 0.03846057, 0.03728885,\n",
       "        0.03656052, 0.0361214 , 0.03583296, 0.03564199, 0.03551136]),\n",
       " array([1.        , 0.04537312, 0.04070332, 0.03818408, 0.03700449,\n",
       "        0.03627033, 0.03582853, 0.03553835, 0.03534645, 0.03521524]),\n",
       " array([1.        , 0.04543632, 0.04077073, 0.03826982, 0.03709802,\n",
       "        0.03637027, 0.03593253, 0.03564527, 0.03545539, 0.03532561]),\n",
       " array([1.        , 0.04584595, 0.04116647, 0.03864463, 0.03745555,\n",
       "        0.03671563, 0.03626872, 0.03597509, 0.03578065, 0.03564768])]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dM_before_one_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
