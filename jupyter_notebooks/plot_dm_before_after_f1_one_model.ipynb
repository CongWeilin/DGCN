{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from utils import load_data, process_graph_data\n",
    "from utils import package_mxl, adj_rw_norm\n",
    "from utils import sparse_mx_to_torch_sparse_tensor\n",
    "from utils import ResultRecorder\n",
    "\n",
    "from model import GCN, GCNBias, SGC, ResGCN, GCNII, APPNP\n",
    "from layers import GraphConv\n",
    "from load_semigcn_data import load_data_gcn\n",
    "from data_loader import DataLoader\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import pairwise_distances\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mticker\n",
    "from scipy.sparse.csgraph import connected_components\n",
    "\n",
    "from tqdm import trange\n",
    "import numpy as np\n",
    "import copy \n",
    "import time\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "DATASET = 'citeseer'\n",
    "SAVE_DIR = './exp_results/figures/%s/'%DATASET\n",
    "\n",
    "layers = [i for i in range(2,11)]\n",
    "repeats = [i for i in range(10)]   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sigW_mean(sigW):\n",
    "    results = []\n",
    "    for k, v in sigW.items():\n",
    "        results.append(v)\n",
    "    return np.mean(results)\n",
    "\n",
    "def get_result(ALGORITHM, layer, repeat):\n",
    "    save_path = os.path.join('exp_results/%s/'%DATASET, \n",
    "                             'results_%s_L%d_repteat%d.pkl'%(DATASET, layer, repeat))\n",
    "    with open(save_path, 'rb') as f:\n",
    "        results_list = pickle.load(f)\n",
    "\n",
    "    result = None\n",
    "    for result_ in results_list:\n",
    "        if result_.note == '%s (L=%d)'%(ALGORITHM, layer):\n",
    "            result = result_\n",
    "            break\n",
    "            \n",
    "    return result.dM_before, result.dM_after, result.test_acc, \\\n",
    "            get_sigW_mean(result.w_sigval_before), get_sigW_mean(result.w_sigval_after)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dM_before = []\n",
    "dM_after = []\n",
    "test_acc = []\n",
    "w_sigval_before = []\n",
    "w_sigval_after = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_DIR = '/home/weilin/Downloads/result_one_model/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/weilin/anaconda3/lib/python3.7/site-packages/numpy/core/fromnumeric.py:3335: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/home/weilin/anaconda3/lib/python3.7/site-packages/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/home/weilin/anaconda3/lib/python3.7/site-packages/numpy/core/fromnumeric.py:3335: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/home/weilin/anaconda3/lib/python3.7/site-packages/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "layer = 10\n",
    "for ALGORITHM in ['GCN', 'GCNBias', 'SGC', 'ResGCN', 'GCNII', 'APPNP']:\n",
    "\n",
    "    dM_before = []\n",
    "    dM_after = []\n",
    "    test_acc = []\n",
    "    w_sigval_before = []\n",
    "    w_sigval_after = []\n",
    "    for repeat in range(10):\n",
    "        dM_before_, dM_after_, test_acc_, w_sigval_before_, w_sigval_after_ = get_result(ALGORITHM, layer, repeat)\n",
    "        dM_before.append(dM_before_)\n",
    "        dM_after.append(dM_after_)\n",
    "        test_acc.append(test_acc_)\n",
    "        w_sigval_before.append(w_sigval_before_)\n",
    "        w_sigval_after.append(w_sigval_after_)\n",
    "        \n",
    "    # plot dM_before\n",
    "    fig, axs = plt.subplots()\n",
    "    \n",
    "    y_vals = np.mean(dM_before, axis=0)\n",
    "    y_vals_0 = y_vals[0]\n",
    "    y_vals = y_vals/y_vals_0\n",
    "    y_stds = np.std(dM_before, axis=0)\n",
    "    y_stds = y_stds/y_vals_0\n",
    "    x_vals = np.arange(len(y_vals))\n",
    "\n",
    "    w_sig_mean, w_sig_stds = np.mean(w_sigval_before), np.std(w_sigval_before)\n",
    "    axs.plot(x_vals, y_vals, label='Before training ($\\lambda_{\\max}$(W) = %.3f $\\pm$ %.3f)'%(w_sig_mean, w_sig_stds))\n",
    "    axs.fill_between(x_vals, y_vals-y_stds, y_vals+y_stds ,alpha=0.3)\n",
    "\n",
    "    plt.title('%s: $d_M(H^{(\\ell)}) / d_M(H^{(0)})$ / Num of layers'%ALGORITHM)\n",
    "    axs.set_xlabel('Num of layers')\n",
    "    axs.set_ylabel('$d_M(H^{(\\ell)}) / d_M(H^{(0)})$')\n",
    "    axs.grid(True)\n",
    "    plt.gca().xaxis.set_major_locator(mticker.MultipleLocator(1))\n",
    "    fig.tight_layout()\n",
    "    plt.legend()\n",
    "    plt.savefig(SAVE_DIR+'dM_before_%s.pdf'%(ALGORITHM))\n",
    "    plt.close()\n",
    "    \n",
    "    # plot dM_after\n",
    "    fig, axs = plt.subplots()\n",
    "\n",
    "    y_vals = np.mean(dM_after, axis=0)\n",
    "    y_vals_0 = y_vals[0]\n",
    "    y_vals = y_vals/y_vals_0\n",
    "    y_stds = np.std(dM_after, axis=0)\n",
    "    y_stds = y_stds/y_vals_0\n",
    "    x_vals = np.arange(len(y_vals))\n",
    "\n",
    "    w_sig_mean, w_sig_stds = np.mean(w_sigval_after), np.std(w_sigval_after)\n",
    "    axs.plot(x_vals, y_vals, label='After training ($\\lambda_{\\max}$(W) = %.3f $\\pm$ %.3f)'%(w_sig_mean, w_sig_stds))\n",
    "    axs.fill_between(x_vals, y_vals-y_stds, y_vals+y_stds ,alpha=0.3)\n",
    "\n",
    "    plt.title('%s: $d_M(H^{(\\ell)}) / d_M(H^{(0)})$ / Num of layers'%ALGORITHM)\n",
    "    axs.set_xlabel('Num of layers')\n",
    "    axs.set_ylabel('$d_M(H^{(\\ell)}) / d_M(H^{(0)})$')\n",
    "    axs.grid(True)\n",
    "    plt.gca().xaxis.set_major_locator(mticker.MultipleLocator(1))\n",
    "    fig.tight_layout()\n",
    "    plt.legend()\n",
    "    plt.savefig(SAVE_DIR+'dM_after_%s.pdf'%(ALGORITHM))\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# layer = 10\n",
    "\n",
    "# fig, axs = plt.subplots()\n",
    "\n",
    "# for ALGORITHM in ['GCN', 'ResGCN', 'GCNII']:\n",
    "    \n",
    "#     color = next(axs._get_lines.prop_cycler)['color']\n",
    "    \n",
    "#     dM_before = []\n",
    "#     dM_after = []\n",
    "#     test_acc = []\n",
    "#     w_sigval_before = []\n",
    "#     w_sigval_after = []\n",
    "#     for repeat in range(10):\n",
    "#         dM_before_, dM_after_, test_acc_, w_sigval_before_, w_sigval_after_ = get_result(ALGORITHM, layer, repeat)\n",
    "#         dM_before.append(dM_before_)\n",
    "#         dM_after.append(dM_after_)\n",
    "#         test_acc.append(test_acc_)\n",
    "#         w_sigval_before.append(w_sigval_before_)\n",
    "#         w_sigval_after.append(w_sigval_after_)\n",
    "\n",
    "#     # plot dM_before\n",
    "#     y_vals = np.mean(dM_before, axis=0)\n",
    "#     y_vals_0 = y_vals[0]\n",
    "#     y_vals = y_vals/y_vals_0\n",
    "#     y_stds = np.std(dM_before, axis=0)\n",
    "#     y_stds = y_stds/y_vals_0\n",
    "#     x_vals = np.arange(len(y_vals))\n",
    "\n",
    "#     w_sig_mean, w_sig_stds = np.mean(w_sigval_before), np.std(w_sigval_before)\n",
    "#     axs.plot(x_vals, y_vals, color=color, linestyle='--',\n",
    "#              label='%s: Before training ($\\lambda_{\\max}$(W) = %.3f $\\pm$ %.3f)'%(ALGORITHM, w_sig_mean, w_sig_stds))\n",
    "#     axs.fill_between(x_vals, y_vals-y_stds, y_vals+y_stds ,alpha=0.3, color=color)\n",
    "    \n",
    "#     # plot dM_after\n",
    "#     y_vals = np.mean(dM_after, axis=0)\n",
    "#     y_vals_0 = y_vals[0]\n",
    "#     y_vals = y_vals/y_vals_0\n",
    "#     y_stds = np.std(dM_after, axis=0)\n",
    "#     y_stds = y_stds/y_vals_0\n",
    "#     x_vals = np.arange(len(y_vals))\n",
    "\n",
    "#     w_sig_mean, w_sig_stds = np.mean(w_sigval_after), np.std(w_sigval_after)\n",
    "#     axs.plot(x_vals, y_vals, color=color, linestyle='-',\n",
    "#              label='%s: After training ($\\lambda_{\\max}$(W) = %.3f $\\pm$ %.3f)'%(ALGORITHM, w_sig_mean, w_sig_stds))\n",
    "#     axs.fill_between(x_vals, y_vals-y_stds, y_vals+y_stds ,alpha=0.3, color=color)\n",
    "\n",
    "# plt.title('Citeseer: $d_M(H^{(\\ell)}) / d_M(H^{(0)})$ / Num of layers')\n",
    "# axs.set_xlabel('Num of layers')\n",
    "# axs.set_ylabel('$d_M(H^{(\\ell)}) / d_M(H^{(0)})$')\n",
    "# axs.grid(True)\n",
    "# plt.gca().xaxis.set_major_locator(mticker.MultipleLocator(1))\n",
    "# fig.tight_layout()\n",
    "# plt.legend()\n",
    "    \n",
    "# plt.ylim(0, 2)\n",
    "# plt.savefig(SAVE_DIR+'dM_before_after.pdf')\n",
    "# # plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/weilin/Downloads/result_one_model/'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SAVE_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
